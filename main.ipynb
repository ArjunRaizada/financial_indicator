{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the folder path\n",
    "folder_path = 'nifty_50'\n",
    "\n",
    "# Initialize an empty dictionary to store the dataframes\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Extract company name (removing '.csv' and converting to lowercase)\n",
    "        company_name = file_name.replace('.csv', '').lower()\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(folder_path, file_name))\n",
    "        # Assign the DataFrame to the dictionary with the formatted name\n",
    "        dataframes[f\"df_{company_name}\"] = df\n",
    "\n",
    "# Access individual dataframes using dataframes['df_companyname']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataframes\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframes' is not defined"
     ]
    }
   ],
   "source": [
    "dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store processed data\n",
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talib\n",
    "# Loop through each company's DataFrame\n",
    "for key, df in dataframes.items():\n",
    "    # Ensure DataFrame is sorted by Date\n",
    "    df = df.sort_values('Date')\n",
    "    \n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Extract necessary columns and rename them if needed\n",
    "    df = df[['Date', 'Symbol', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "    \n",
    "    # Handle missing values\n",
    "    df.dropna(subset=['Open', 'High', 'Low', 'Close', 'Volume'], inplace=True)\n",
    "    \n",
    "    # Convert 'Date' to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Calculate technical indicators\n",
    "    # 1. MACD\n",
    "    df['MACD'], df['MACD_Signal'], df['MACD_Hist'] = talib.MACD(\n",
    "        df['Close'], fastperiod=12, slowperiod=26, signalperiod=9\n",
    "    )\n",
    "    \n",
    "    # 2. RSI\n",
    "    df['RSI'] = talib.RSI(df['Close'], timeperiod=14)\n",
    "    \n",
    "    # 3. Bollinger Bands\n",
    "    df['Upper_BB'], df['Middle_BB'], df['Lower_BB'] = talib.BBANDS(\n",
    "        df['Close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0\n",
    "    )\n",
    "    \n",
    "    # 4. Stochastic Oscillator\n",
    "    df['SlowK'], df['SlowD'] = talib.STOCH(\n",
    "        df['High'], df['Low'], df['Close'],\n",
    "        fastk_period=14, slowk_period=3, slowk_matype=0,\n",
    "        slowd_period=3, slowd_matype=0\n",
    "    )\n",
    "    \n",
    "    # Fill NaN values resulting from indicator calculations\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    # Calculate Future Price Change Percentage (e.g., 5 days ahead)\n",
    "    prediction_window = 5\n",
    "    df['Future_Close'] = df['Close'].shift(-prediction_window)\n",
    "    df['Price_Change_Percent'] = ((df['Future_Close'] - df['Close']) / df['Close']) * 100\n",
    "    \n",
    "    # Assign labels based on Price Change and MACD\n",
    "    def assign_label(row):\n",
    "        macd_bullish = row['MACD'] > row['MACD_Signal']\n",
    "        macd_bearish = row['MACD'] < row['MACD_Signal']\n",
    "        if (row['Price_Change_Percent'] > 2.0) and macd_bullish:\n",
    "            return 'Buy'\n",
    "        elif (row['Price_Change_Percent'] < -2.0) and macd_bearish:\n",
    "            return 'Sell'\n",
    "        else:\n",
    "            return 'Hold'\n",
    "    \n",
    "    df['Target'] = df.apply(assign_label, axis=1)\n",
    "    \n",
    "    # Drop rows with NaN in 'Target' or 'Future_Close'\n",
    "    df.dropna(subset=['Target', 'Future_Close'], inplace=True)\n",
    "    \n",
    "    # Append processed DataFrame to the list\n",
    "    all_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Combine Data from All Companies\n",
    "combined_df = pd.concat(all_data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Sort Combined DataFrame by Date\n",
    "combined_df = combined_df.sort_values('Date').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define Features and Target\n",
    "feature_columns = [\n",
    "    'Open', 'High', 'Low', 'Close', 'Volume', 'MACD', 'MACD_Signal',\n",
    "    'MACD_Hist', 'RSI', 'Upper_BB', 'Middle_BB', 'Lower_BB', 'SlowK', 'SlowD'\n",
    "]\n",
    "\n",
    "X = combined_df[feature_columns]\n",
    "y = combined_df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/label_encoder.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "# 5. Encode Target Labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)  # 'Buy'=0, 'Hold'=1, 'Sell'=2\n",
    "\n",
    "# Save label encoder for future use\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "joblib.dump(label_encoder, 'models/label_encoder.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Handle Missing Values in Features\n",
    "X.fillna(method='bfill', inplace=True)\n",
    "X.fillna(method='ffill', inplace=True)\n",
    "X.dropna(inplace=True)\n",
    "\n",
    "# Adjust y_encoded accordingly\n",
    "y_encoded = y_encoded[X.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Initialize TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Initialize a Dictionary to Store Results for Each Model\n",
    "model_metrics = {\n",
    "    'Random Forest': [],\n",
    "    'XGBoost': [],\n",
    "    'LightGBM': [],\n",
    "    'CatBoost': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Counter\n",
      "  Downloading Counter-1.0.0.tar.gz (5.2 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: Counter\n",
      "  Building wheel for Counter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Counter: filename=Counter-1.0.0-py3-none-any.whl size=5394 sha256=75b2829a11df38e922061860779a9f1e0aa5e1899ad5a19e3b09184acd6bcc91\n",
      "  Stored in directory: /Users/arjunraizada/Library/Caches/pip/wheels/16/ff/7a/6e8bf2fdadb47c50a03bb4b9a59bd2b1da1b876faf8e3815d9\n",
      "Successfully built Counter\n",
      "Installing collected packages: Counter\n",
      "Successfully installed Counter-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 78319, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Fold 2\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 156634, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Fold 3\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 234949, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Fold 4\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 313264, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "Fold 5\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 391579, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n"
     ]
    }
   ],
   "source": [
    "# 9. Iterate Over Each Fold\n",
    "from sklearn.preprocessing import  StandardScaler\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv.split(X), 1):\n",
    "    print(f\"Fold {fold}\")\n",
    "    # Split the data\n",
    "    X_train_cv = X.iloc[train_index]\n",
    "    X_test_cv = X.iloc[test_index]\n",
    "    y_train_cv = y_encoded[train_index]\n",
    "    y_test_cv = y_encoded[test_index]\n",
    "    \n",
    "    # Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_cv)\n",
    "    X_test_scaled = scaler.transform(X_test_cv)\n",
    "    \n",
    "    # Save scaler for each fold if needed\n",
    "    # joblib.dump(scaler, f'models/scaler_fold_{fold}.pkl')\n",
    "    \n",
    "    # Handle Class Weights\n",
    "    counter = Counter(y_train_cv)\n",
    "    majority = max(counter.values())\n",
    "    class_weights = {cls: float(majority)/count for cls, count in counter.items()}\n",
    "    \n",
    "    # Convert class_weights to a list for CatBoost\n",
    "    class_weights_list = [class_weights[i] for i in sorted(class_weights.keys())]\n",
    "    \n",
    "    # ---------------------\n",
    "    # Train Random Forest\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "    rf_model.fit(X_train_scaled, y_train_cv)\n",
    "    y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "    acc_rf = accuracy_score(y_test_cv, y_pred_rf)\n",
    "    f1_rf = f1_score(y_test_cv, y_pred_rf, average='macro')\n",
    "    model_metrics['Random Forest'].append({'accuracy': acc_rf, 'f1_macro': f1_rf})\n",
    "    \n",
    "    # ---------------------\n",
    "    # Train XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=6,\n",
    "        objective='multi:softprob',\n",
    "        num_class=3,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=42,\n",
    "        scale_pos_weight=1  # Adjusted if necessary\n",
    "    )\n",
    "    xgb_model.fit(X_train_scaled, y_train_cv)\n",
    "    y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "    acc_xgb = accuracy_score(y_test_cv, y_pred_xgb)\n",
    "    f1_xgb = f1_score(y_test_cv, y_pred_xgb, average='macro')\n",
    "    model_metrics['XGBoost'].append({'accuracy': acc_xgb, 'f1_macro': f1_xgb})\n",
    "    \n",
    "    # ---------------------\n",
    "    # Train LightGBM\n",
    "    lgb_model = lgb.LGBMClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        objective='multiclass',\n",
    "        class_weight=class_weights,\n",
    "        random_state=42\n",
    "    )\n",
    "    lgb_model.fit(X_train_scaled, y_train_cv)\n",
    "    y_pred_lgb = lgb_model.predict(X_test_scaled)\n",
    "    acc_lgb = accuracy_score(y_test_cv, y_pred_lgb)\n",
    "    f1_lgb = f1_score(y_test_cv, y_pred_lgb, average='macro')\n",
    "    model_metrics['LightGBM'].append({'accuracy': acc_lgb, 'f1_macro': f1_lgb})\n",
    "    \n",
    "    # ---------------------\n",
    "    # Train CatBoost\n",
    "    cat_model = CatBoostClassifier(\n",
    "        iterations=100,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        loss_function='MultiClass',\n",
    "        random_seed=42,\n",
    "        verbose=0,\n",
    "        class_weights=class_weights_list\n",
    "    )\n",
    "    cat_model.fit(X_train_scaled, y_train_cv)\n",
    "    y_pred_cat = cat_model.predict(X_test_scaled)\n",
    "    acc_cat = accuracy_score(y_test_cv, y_pred_cat)\n",
    "    f1_cat = f1_score(y_test_cv, y_pred_cat, average='macro')\n",
    "    model_metrics['CatBoost'].append({'accuracy': acc_cat, 'f1_macro': f1_cat})\n",
    "    \n",
    "    # Optionally, print classification reports for each model\n",
    "    # print(\"Random Forest Classification Report:\")\n",
    "    # print(classification_report(y_test_cv, y_pred_rf, target_names=label_encoder.classes_))\n",
    "    # Similarly for other models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest ===\n",
      "Average Accuracy: 0.6635\n",
      "Average Macro F1-Score: 0.3604\n",
      "\n",
      "\n",
      "=== XGBoost ===\n",
      "Average Accuracy: 0.6849\n",
      "Average Macro F1-Score: 0.3023\n",
      "\n",
      "\n",
      "=== LightGBM ===\n",
      "Average Accuracy: 0.3388\n",
      "Average Macro F1-Score: 0.3537\n",
      "\n",
      "\n",
      "=== CatBoost ===\n",
      "Average Accuracy: 0.3064\n",
      "Average Macro F1-Score: 0.3137\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Aggregate and Display Results\n",
    "def aggregate_metrics(metrics_list, model_name):\n",
    "    accuracies = [m['accuracy'] for m in metrics_list]\n",
    "    f1_scores = [m['f1_macro'] for m in metrics_list]\n",
    "    print(f\"=== {model_name} ===\")\n",
    "    print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
    "    print(f\"Average Macro F1-Score: {np.mean(f1_scores):.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "for model_name, metrics in model_metrics.items():\n",
    "    aggregate_metrics(metrics, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Train Final Models on Entire Training Data (excluding final test set)\n",
    "\n",
    "# Get the indices for all folds\n",
    "folds = list(tscv.split(X))\n",
    "train_indices = []\n",
    "for i in range(len(folds) - 1):  # Exclude the last fold for final testing\n",
    "    train_indices.extend(folds[i][0])\n",
    "final_test_index = folds[-1][1]\n",
    "\n",
    "X_train_final = X.iloc[train_indices]\n",
    "y_train_final = y_encoded[train_indices]\n",
    "X_test_final = X.iloc[final_test_index]\n",
    "y_test_final = y_encoded[final_test_index]\n",
    "\n",
    "# Feature Scaling\n",
    "scaler_final = StandardScaler()\n",
    "X_train_final_scaled = scaler_final.fit_transform(X_train_final)\n",
    "X_test_final_scaled = scaler_final.transform(X_test_final)\n",
    "\n",
    "# Save the final scaler\n",
    "joblib.dump(scaler_final, 'models/scaler_final.pkl')\n",
    "\n",
    "# Handle Class Weights\n",
    "counter_final = Counter(y_train_final)\n",
    "majority_final = max(counter_final.values())\n",
    "class_weights_final = {cls: float(majority_final)/count for cls, count in counter_final.items()}\n",
    "\n",
    "# Convert class_weights to a list for CatBoost (if needed)\n",
    "class_weights_list_final = [class_weights_final[i] for i in sorted(class_weights_final.keys())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/random_forest_final.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final Random Forest model\n",
    "final_rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    class_weight=class_weights_final\n",
    ")\n",
    "final_rf_model.fit(X_train_final_scaled, y_train_final)\n",
    "\n",
    "# Save the final Random Forest model\n",
    "joblib.dump(final_rf_model, 'models/random_forest_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Random Forest Model Evaluation ===\n",
      "Accuracy: 0.6698\n",
      "Macro F1-Score: 0.3479\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Buy       0.36      0.10      0.16     12523\n",
      "        Hold       0.70      0.93      0.80     54370\n",
      "        Sell       0.29      0.05      0.09     11422\n",
      "\n",
      "    accuracy                           0.67     78315\n",
      "   macro avg       0.45      0.36      0.35     78315\n",
      "weighted avg       0.58      0.67      0.59     78315\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1250 11273     0]\n",
      " [ 2270 50586  1514]\n",
      " [    0 10802   620]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# Evaluate the final Random Forest model on the test set\n",
    "y_pred_rf_final = final_rf_model.predict(X_test_final_scaled)\n",
    "acc_rf_final = accuracy_score(y_test_final, y_pred_rf_final)\n",
    "f1_rf_final = f1_score(y_test_final, y_pred_rf_final, average='macro')\n",
    "\n",
    "print(\"=== Final Random Forest Model Evaluation ===\")\n",
    "print(f\"Accuracy: {acc_rf_final:.4f}\")\n",
    "print(f\"Macro F1-Score: {f1_rf_final:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_final, y_pred_rf_final, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_final, y_pred_rf_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/xgboost_final.pkl']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the final XGBoost model\n",
    "final_xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    objective='multi:softprob',\n",
    "    num_class=3,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42,\n",
    "    scale_pos_weight=1  # Adjusted if necessary\n",
    ")\n",
    "final_xgb_model.fit(X_train_final_scaled, y_train_final)\n",
    "\n",
    "# Save the final XGBoost model\n",
    "joblib.dump(final_xgb_model, 'models/xgboost_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final XGBoost Model Evaluation ===\n",
      "Accuracy: 0.6833\n",
      "Macro F1-Score: 0.3144\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Buy       0.46      0.03      0.05     12523\n",
      "        Hold       0.70      0.97      0.81     54370\n",
      "        Sell       0.29      0.05      0.09     11422\n",
      "\n",
      "    accuracy                           0.68     78315\n",
      "   macro avg       0.48      0.35      0.31     78315\n",
      "weighted avg       0.60      0.68      0.58     78315\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  320 12203     0]\n",
      " [  372 52622  1376]\n",
      " [    0 10850   572]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the final XGBoost model on the test set\n",
    "y_pred_xgb_final = final_xgb_model.predict(X_test_final_scaled)\n",
    "acc_xgb_final = accuracy_score(y_test_final, y_pred_xgb_final)\n",
    "f1_xgb_final = f1_score(y_test_final, y_pred_xgb_final, average='macro')\n",
    "\n",
    "print(\"=== Final XGBoost Model Evaluation ===\")\n",
    "print(f\"Accuracy: {acc_xgb_final:.4f}\")\n",
    "print(f\"Macro F1-Score: {f1_xgb_final:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_final, y_pred_xgb_final, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_final, y_pred_xgb_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Voting Classifier Model Evaluation ===\n",
      "Accuracy: 0.6876\n",
      "Macro F1-Score: 0.3136\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Buy       0.43      0.04      0.07     12523\n",
      "        Hold       0.70      0.97      0.81     54370\n",
      "        Sell       0.33      0.03      0.06     11422\n",
      "\n",
      "    accuracy                           0.69     78315\n",
      "   macro avg       0.49      0.35      0.31     78315\n",
      "weighted avg       0.60      0.69      0.58     78315\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  482 12041     0]\n",
      " [  630 53008   732]\n",
      " [    0 11062   360]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Initialize the ensemble with the two models\n",
    "final_voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', final_rf_model),\n",
    "        ('xgb', final_xgb_model)\n",
    "    ],\n",
    "    voting='soft'  # Use soft voting to average predicted probabilities\n",
    ")\n",
    "\n",
    "# Train the ensemble (since models are already trained, fit may not be necessary)\n",
    "# But for safety, we can retrain on the same data\n",
    "final_voting_clf.fit(X_train_final_scaled, y_train_final)\n",
    "\n",
    "# Save the ensemble model\n",
    "joblib.dump(final_voting_clf, 'models/voting_classifier_final.pkl')\n",
    "\n",
    "# Evaluate the ensemble model on the test set\n",
    "y_pred_voting_final = final_voting_clf.predict(X_test_final_scaled)\n",
    "acc_voting_final = accuracy_score(y_test_final, y_pred_voting_final)\n",
    "f1_voting_final = f1_score(y_test_final, y_pred_voting_final, average='macro')\n",
    "\n",
    "print(\"=== Final Voting Classifier Model Evaluation ===\")\n",
    "print(f\"Accuracy: {acc_voting_final:.4f}\")\n",
    "print(f\"Macro F1-Score: {f1_voting_final:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_final, y_pred_voting_final, target_names=label_encoder.classes_))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_final, y_pred_voting_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>MACD_Hist</th>\n",
       "      <th>RSI</th>\n",
       "      <th>Upper_BB</th>\n",
       "      <th>Middle_BB</th>\n",
       "      <th>Lower_BB</th>\n",
       "      <th>SlowK</th>\n",
       "      <th>SlowD</th>\n",
       "      <th>Future_Close</th>\n",
       "      <th>Price_Change_Percent</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>BAJAUTOFIN</td>\n",
       "      <td>49.45</td>\n",
       "      <td>50.75</td>\n",
       "      <td>46.5</td>\n",
       "      <td>50.75</td>\n",
       "      <td>7600</td>\n",
       "      <td>-0.241281</td>\n",
       "      <td>-0.674671</td>\n",
       "      <td>0.43339</td>\n",
       "      <td>30.788177</td>\n",
       "      <td>48.473312</td>\n",
       "      <td>41.515</td>\n",
       "      <td>34.556688</td>\n",
       "      <td>15.668777</td>\n",
       "      <td>21.354488</td>\n",
       "      <td>42.9</td>\n",
       "      <td>-15.467980</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>BAJAUTOFIN</td>\n",
       "      <td>53.20</td>\n",
       "      <td>53.20</td>\n",
       "      <td>47.9</td>\n",
       "      <td>48.10</td>\n",
       "      <td>5000</td>\n",
       "      <td>-0.241281</td>\n",
       "      <td>-0.674671</td>\n",
       "      <td>0.43339</td>\n",
       "      <td>30.788177</td>\n",
       "      <td>48.473312</td>\n",
       "      <td>41.515</td>\n",
       "      <td>34.556688</td>\n",
       "      <td>15.668777</td>\n",
       "      <td>21.354488</td>\n",
       "      <td>40.1</td>\n",
       "      <td>-16.632017</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>BAJAUTOFIN</td>\n",
       "      <td>46.55</td>\n",
       "      <td>47.40</td>\n",
       "      <td>44.6</td>\n",
       "      <td>44.60</td>\n",
       "      <td>3500</td>\n",
       "      <td>-0.241281</td>\n",
       "      <td>-0.674671</td>\n",
       "      <td>0.43339</td>\n",
       "      <td>30.788177</td>\n",
       "      <td>48.473312</td>\n",
       "      <td>41.515</td>\n",
       "      <td>34.556688</td>\n",
       "      <td>15.668777</td>\n",
       "      <td>21.354488</td>\n",
       "      <td>39.0</td>\n",
       "      <td>-12.556054</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>BAJAUTOFIN</td>\n",
       "      <td>43.50</td>\n",
       "      <td>46.00</td>\n",
       "      <td>42.1</td>\n",
       "      <td>45.25</td>\n",
       "      <td>6200</td>\n",
       "      <td>-0.241281</td>\n",
       "      <td>-0.674671</td>\n",
       "      <td>0.43339</td>\n",
       "      <td>30.788177</td>\n",
       "      <td>48.473312</td>\n",
       "      <td>41.515</td>\n",
       "      <td>34.556688</td>\n",
       "      <td>15.668777</td>\n",
       "      <td>21.354488</td>\n",
       "      <td>39.5</td>\n",
       "      <td>-12.707182</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>BAJAUTOFIN</td>\n",
       "      <td>48.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>42.0</td>\n",
       "      <td>42.90</td>\n",
       "      <td>3500</td>\n",
       "      <td>-0.241281</td>\n",
       "      <td>-0.674671</td>\n",
       "      <td>0.43339</td>\n",
       "      <td>30.788177</td>\n",
       "      <td>48.473312</td>\n",
       "      <td>41.515</td>\n",
       "      <td>34.556688</td>\n",
       "      <td>15.668777</td>\n",
       "      <td>21.354488</td>\n",
       "      <td>39.9</td>\n",
       "      <td>-6.993007</td>\n",
       "      <td>Hold</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date      Symbol   Open   High   Low  Close  Volume      MACD  \\\n",
       "0 2000-01-03  BAJAUTOFIN  49.45  50.75  46.5  50.75    7600 -0.241281   \n",
       "1 2000-01-04  BAJAUTOFIN  53.20  53.20  47.9  48.10    5000 -0.241281   \n",
       "2 2000-01-05  BAJAUTOFIN  46.55  47.40  44.6  44.60    3500 -0.241281   \n",
       "3 2000-01-06  BAJAUTOFIN  43.50  46.00  42.1  45.25    6200 -0.241281   \n",
       "4 2000-01-07  BAJAUTOFIN  48.00  48.00  42.0  42.90    3500 -0.241281   \n",
       "\n",
       "   MACD_Signal  MACD_Hist        RSI   Upper_BB  Middle_BB   Lower_BB  \\\n",
       "0    -0.674671    0.43339  30.788177  48.473312     41.515  34.556688   \n",
       "1    -0.674671    0.43339  30.788177  48.473312     41.515  34.556688   \n",
       "2    -0.674671    0.43339  30.788177  48.473312     41.515  34.556688   \n",
       "3    -0.674671    0.43339  30.788177  48.473312     41.515  34.556688   \n",
       "4    -0.674671    0.43339  30.788177  48.473312     41.515  34.556688   \n",
       "\n",
       "       SlowK      SlowD  Future_Close  Price_Change_Percent Target  \n",
       "0  15.668777  21.354488          42.9            -15.467980   Hold  \n",
       "1  15.668777  21.354488          40.1            -16.632017   Hold  \n",
       "2  15.668777  21.354488          39.0            -12.556054   Hold  \n",
       "3  15.668777  21.354488          39.5            -12.707182   Hold  \n",
       "4  15.668777  21.354488          39.9             -6.993007   Hold  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
